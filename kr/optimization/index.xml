<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>다정이 노트</title>
    <link>https://dahjeong.github.io/kr/optimization/</link>
    <description>Recent content on 다정이 노트</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2018, Dajung Kim; all rights reserved.</copyright>
    <lastBuildDate>Thu, 14 Apr 2022 00:00:00 +0800</lastBuildDate><atom:link href="https://dahjeong.github.io/kr/optimization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Gradient-free Optimization</title>
      <link>https://dahjeong.github.io/kr/optimization/gradient-free/</link>
      <pubDate>Thu, 14 Apr 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/gradient-free/</guid>
      <description>
        
          
            Gradient-Free Optimization 이건 언제 사용하는 거냐? gradient가 계산하기 복잡하거나 계산을 할 수 없는 경우(function evaluation 값이 noisy하거나 아니면 목적 함수가 continuous 하지 않거나, 블랙박스로 싸여있는 legacy 코드라 고칠수가 없는데 noisy하거나 어떤 값이 나오는지 알 수 없을 경우거나, 어떤 경우에 아예 에러가 나오는데 최적화를 수행해야 할 때)에 gradient-free optimization이 유용하게 사용될 수 있다. multi-modal function을 최적화 할때 gradient-free optimization을 사용하여 global optimum을 얻기도 하는데 gradient-free optimization이라고 해서 모든 방법이 global optimum을 주는 것은 아니다.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Multiobjective Optimization</title>
      <link>https://dahjeong.github.io/kr/optimization/multiobjective/</link>
      <pubDate>Thu, 14 Apr 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/multiobjective/</guid>
      <description>
        
          
            Multiobjective Optimization 최적화 문제에서 목적함수 objective가 여러개 (주로 2, 3, 4정도) 있는 경우에 다목적 최적화 multiobjective optimization 를 수행한다. 근데 결국에는 하나를 선택해야 될 것인데 왜 다목적 최적화가 필요한 것인가? 그 이유는
objectives의 tradeoff를 quantify 할 수 있기 때문이다. - 보통 objectives 들에 어떤 커플링이 있는데 mutliobjective optimization을 통해서 design variable의 변화에 대한 objectives의 sensitivty 를 알 수 있어서 최종 결정에 도움을 줄 수 있다. 실제로 하나의 design을 하는게 아니라 여러 option을 어떤 executive committee 같은 곳에 제시해야 하는 경우가 있다.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Sampling Methods</title>
      <link>https://dahjeong.github.io/kr/optimization/sampling-methods/</link>
      <pubDate>Thu, 14 Apr 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/sampling-methods/</guid>
      <description>
        
          
            Sampling Methods sampling method 중에서도 optimization에서 주로 쓰이는 방법은 random sampling, Latin Hypercube Sampling(LHS), Low-discrepancy sequences 중에 하나인 Halton sequence이다. ramdom sampling은 그냥 random하게 sample을 선택하는 방법인데 이게, 도메인을 골고루 커버하지 못 할수가 있다. 특히 sampling 수를 줄이면 결과가 더 안좋은데 그래서 Latin Hypercube Sampling이 이를 개선한다.
Latin Hypercube Sampling 일단 LHS의 결과를 보면 아래 그림과 같다.
가로축으로 한 칸 한 칸씩 이동하면서 보면 완전히 비어 있는 열이 없고 세로축으로 한 칸 한 칸씩 이동하면서 봐도 완전히 비어있는 행이 없다.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Discrete Optimization</title>
      <link>https://dahjeong.github.io/kr/optimization/discrete/</link>
      <pubDate>Wed, 13 Apr 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/discrete/</guid>
      <description>
        
          
            Discrete Optimization Optimization의 Design variables가 discrete한 문제를 discrete optimization problem이라고 한다. 이는 discrete variable의 종류에 따라 3가지로 분류될 수 있다.
binary (0 or 1) integer (vehivle의 wheel의 갯수 등을 선택하는 문제) discrete (예를 들어 금속의 종류를 선택한다거나 등의 문제) discrte opimization은 nondeterministic polynomial time complete 이므로 solution이 최적인 것을 verify할 수 있지만 solution을 효율적으로 구하는 방법이 없다. 그래서 주로 huristic 한 방법을 이용한다.
Discrete optimization을 피하는 방법 Continuous variable이 discrete variable 보다 더 많은데 이 discrete variable때문에 discrete optimization을 선택해야 한다면 이것을 피하기 위해서 continuous optimization을 돌리고 discrete variable에만 round 하면 됨 그리고 그 variable을 fix한 상태에서 다시 optimization을 돌릴수도 있다.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Penalty Methods</title>
      <link>https://dahjeong.github.io/kr/optimization/penalty/</link>
      <pubDate>Tue, 12 Apr 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/penalty/</guid>
      <description>
        
          
            Penalty method 제약조건이 있는 Constrained optimization을 간단하게 제약조건이 없는 unconstrained optimization으로 변환할 수 있는 방법이다. penalty parameter 설정에 의해서 true optimum에 수렴하지 않을 경우가 있어서 gradient based optimization에서는 더이상 사용되지 않는다. graient free method에서 사용되기도 하고, constrained optimization을 이해하는데 도움이 되기 때문에 살펴보자. 일단 constrained optimization problem의 formulation은 아래와 같다. $$\begin{aligned} \text{minimize} \quad &amp;amp; f(x) &amp;amp; \newline \text{by varying} \quad &amp;amp; x_i &amp;amp; i=1,...,n_x \newline \text{subject to} \quad &amp;amp; g_j(x) \leq 0 &amp;amp; j=1,.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Complex Step</title>
      <link>https://dahjeong.github.io/kr/optimization/complex-step/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/complex-step/</guid>
      <description>
        
          
            Complex step은 수치 미분값을 구하는 방법 중에 하나다. finite differencing을 유도할 때 small step $h$으로 real number가 아니라 imaginary로 취하고 Taylor expansion을 적용하면 아래와 같다. $$f(x+ih) = f(x) + ihf&#39;(x) - \frac{h^2}{2}f&#39;&#39;(x)-\frac{ih^3}{3!}f&#39;&#39;&#39;(x)+\cdots$$
여기서 imaginary part만 모아서 보자. $$\text{Imag}[f(x+ih)] = hf&#39;(x) - \frac{h^3}{3!}f&#39;&#39;&#39;(x)+\cdots$$
위의 방정식을 $f&#39;(x)$로 정리하면 아래와 같다. $$f&#39;(x) = \frac{\text{Imag}[f(x+ih)]}{h} + O(h^2)$$
앞에서 finite differencing에서는 step의 크기가 줄어들면, analytic solution과 비교하였을 때 derivative 값의 오차가 줄어들다가 어느 순간이되면 numerical error로 인해서 (subtraction에 의한 significant number의 문제) step이 줄어들어도 error가 커지는 현상이 발견된다.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Finite Differencing</title>
      <link>https://dahjeong.github.io/kr/optimization/finite-differemcing/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/finite-differemcing/</guid>
      <description>
        
          
            수치적으로 미분값 구하는 방법은 4가지가 있는데 1) symbolic derivative 2) finite differencing 3)complex step method 4) automatic differenciation 이다. 그 중에서 가장 간단하게 자주 쓰이는 방법이 finite differencing 이다. 먼저 symbolic derivative는 함수의 analytic한 derivative를 찾는 방법이다. 예를 들어서 $f=\sin(x)$의 경우에 symbolic derivative는 $f=\cos(x)$이다. 그런데 이 방법은 implicit equation의 경우에 매우 비효율적인 연산이 되거나 계산 자체가 어렵다. 따라서 모든 함수에 symbolic derivative를 적용할 수가 없다.
여기서 잠깐 implicit equation에 대해서 좀 더 자세히 알아보자.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Line Search</title>
      <link>https://dahjeong.github.io/kr/optimization/line-search/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/line-search/</guid>
      <description>
        
          
            $$\underset{x}{\text{minimize}} f(x)$$ 위의 식과 같이 constraint가 없는 최적화 문제에 problem domain이 모든 영역에서 differentiable하면 (미분가능, 이건 연속이랑 다른 개념이라는 걸 고딩 때 배우지) 해당 함수의 gradient, $\nabla f = 0$ 지점이 함수의 극 값, 즉 maximum이나 minimum이 된다. 그래서 최적화 문제 풀 때 $\nabla f(x) = 0$ 의 방정식을 푸는데 (이 방정식을 만족시키는 x를 구한다) 이 과정에서 line search가 나온다.
수치해석적으로 $x$를 적절히 이동시키면서 위의 방정식이 어떤 tolerance $\epsilon$ 내에서 만족되면 연산을 정지한다.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Search Direction</title>
      <link>https://dahjeong.github.io/kr/optimization/search-direction/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/search-direction/</guid>
      <description>
        
          
            Search Direction line search 할 때 어디로 line 그어서 어느 방향으로 이동할 지를 결정해서 one dimensional problem을 반복적으로 푸는 것이다. 오늘은 이 search direction을 어떻게 정하는지 알아 보자. Matines &amp;amp; Andrew 의 text book에서는 아래의 5가지 방법을 소개한다.
Steepest Descent Conjugate Gradient Newton&#39;s Method Quasi-Newton Methods Limited-Memory Quasi-Newton Methods Steepest Descent Gradient가 빠르게 증가하는 반대 방향으로 search direction을 정하는 것이다. $$p = - \nabla f$$ 또는 normalized를 이용하기도 함 $$p = - \frac{\nabla f}{||f||}$$ curvature가 방향에 따라 일정하면 빠르게 수렴한다.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Trust-Region Methods</title>
      <link>https://dahjeong.github.io/kr/optimization/trust-region/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0800</pubDate>
      
      <guid>https://dahjeong.github.io/kr/optimization/trust-region/</guid>
      <description>
        
          
            Trust-Region Methods Line search에서는 방향과 step을 정해서 이동하면서 minimum인지 아닌지 확인하는 반면에 trust region methods에서는 radius를 정해서 그 안에서 approximated function의 minimum을 찾고 그 minimum으로 이동하여 다시 더 큰 radius의 region을 그리고 그 안에서 minimum을 찾는 행위를 반복한다. 최적값으로 수렴하기 전에는 항상 boundary에서 minimum 값을 갖지만 수렴하게되면 radius를 더 크게 해도 boundary 내의 특정 위치를 minimum 값으로 얻고 계산을 반복해도 minimum 값이 바뀌지 않는다. 이를 정리하면 trust-region methods는 아래와 같은 과정으로 진행되고 3번에서 1번으로 반복된다.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
